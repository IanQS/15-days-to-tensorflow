{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I use Tensorflow\n",
      "You use PyTorch\n",
      "Both are great\n"
     ]
    }
   ],
   "source": [
    "with open(\"read_tf.txt\",\"r\") as filer:\n",
    "    print(filer.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data is used to build input pipelines\n",
    "#Former data pipelines made the GPU wait for the CPU to load the data, leading to performance issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=tf.data.TextLineDataset(\"read_tf.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I use Tensorflow'\n",
      "b'You use PyTorch'\n",
      "b'Both are great'\n"
     ]
    }
   ],
   "source": [
    "iterate=input_data.make_one_shot_iterator()\n",
    "next_data=iterate.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        print(sess.run(next_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting words by space \n",
    "input_data=input_data.map(lambda x:tf.string_split([x]).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'I' b'use' b'Tensorflow']\n",
      "[b'You' b'use' b'PyTorch']\n",
      "[b'Both' b'are' b'great']\n"
     ]
    }
   ],
   "source": [
    "iterate=input_data.make_one_shot_iterator()\n",
    "next_data=iterate.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        print(sess.run(next_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'You' b'use' b'PyTorch']\n",
      "[b'Both' b'are' b'great']\n",
      "[b'I' b'use' b'Tensorflow']\n"
     ]
    }
   ],
   "source": [
    "#Shuffling dataset\n",
    "input_data=input_data.shuffle(buffer_size=3) #buffer size is to load data in batches\n",
    "iterate=input_data.make_one_shot_iterator()\n",
    "next_data=iterate.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        print(sess.run(next_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'Both' b'are' b'great']\n",
      " [b'You' b'use' b'PyTorch']]\n",
      "[[b'I' b'use' b'Tensorflow']]\n"
     ]
    }
   ],
   "source": [
    "#create batches\n",
    "new_data_batch=input_data.batch(batch_size=2)#to load data in batches\n",
    "fetcher=new_data_batch.prefetch(buffer_size=1)#always have data in the pipeline\n",
    "iterate=fetcher.make_one_shot_iterator()\n",
    "next_batch_data=iterate.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            print(sess.run(next_batch_data))\n",
    "        except:continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use initializable iterators so that we can chose to “restart” from the beginning.\n",
    "#This will become quite handy when we want to perform multiple epochs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I use Tensorflow'\n",
      "b'You use PyTorch'\n",
      "b'I use Tensorflow'\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TextLineDataset(\"read_tf.txt\")\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "init_op = iterator.initializer\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the iterator\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))\n",
    "    # Move the iterator back to the beginning\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building an image data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.Create the dataset from slices of the filenames and labels\n",
    "#.Shuffle the data with a buffer size equal to the length of the dataset. This ensures good shuffling \n",
    "#.Parse the images from filename to the pixel values. Use multiple threads to improve the speed of preprocessing\n",
    "#.(Optional for training) Data augmentation for the images. Use multiple threads to improve the speed of preprocessing\n",
    "#.Batch the images\n",
    "#.Prefetch one batch to make sure that a batch is ready to be served at all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "import numpy as np\n",
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features,labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From generator We can also initialise a Dataset from a generator, this is useful when we have an array of different elements length (e.g a sequence): In this case we also need specify the types and the shapes of your data that will be used to create the correct tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = np.array([[[1]],[[2],[3]],[[3],[4],[5]]])\n",
    "def generator_seq():\n",
    "    for el in sequence:\n",
    "        yield el\n",
    "dataset_seq = tf.data.Dataset().batch(1).from_generator(generator_seq,\n",
    "                                           output_types= tf.int64, \n",
    "                                           output_shapes=(tf.TensorShape([None, 1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[2]\n",
      " [3]]\n",
      "[[3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "iter = dataset_seq.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Event Title</th>\n",
       "      <th>All Day Event</th>\n",
       "      <th>No End Time</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Contact Email</th>\n",
       "      <th>Contact Phone</th>\n",
       "      <th>Location</th>\n",
       "      <th>Category</th>\n",
       "      <th>Mandatory</th>\n",
       "      <th>Registration</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Last Date To Register</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>3:00:00 PM</td>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Studies Dept. Meeting</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Department meeting</td>\n",
       "      <td>Chris Gallagher</td>\n",
       "      <td>cgallagher@schoolwires.com</td>\n",
       "      <td>814-555-5179</td>\n",
       "      <td>High School</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>9/2/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>6:00:00 PM</td>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>8:00:00 PM</td>\n",
       "      <td>Curriculum Meeting</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Curriculum Meeting</td>\n",
       "      <td>Chris Gallagher</td>\n",
       "      <td>cgallagher@schoolwires.com</td>\n",
       "      <td>814-555-5179</td>\n",
       "      <td>High School</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>9/2/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start Date   Start Time  End Date    End Time                  Event Title   \\\n",
       "0    9/5/2011  3:00:00 PM  9/5/2011         NaN  Social Studies Dept. Meeting   \n",
       "1    9/5/2011  6:00:00 PM  9/5/2011  8:00:00 PM            Curriculum Meeting   \n",
       "\n",
       "  All Day Event No End Time   Event Description         Contact   \\\n",
       "0             N           Y  Department meeting  Chris Gallagher   \n",
       "1             N           N  Curriculum Meeting  Chris Gallagher   \n",
       "\n",
       "                Contact Email Contact Phone     Location  Category Mandatory  \\\n",
       "0  cgallagher@schoolwires.com  814-555-5179  High School         2         N   \n",
       "1  cgallagher@schoolwires.com  814-555-5179  High School         2         N   \n",
       "\n",
       "  Registration  Maximum Last Date To Register  \n",
       "0            N       25              9/2/2011  \n",
       "1            N       25              9/2/2011  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from csv\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"sample.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Start Date ', <tf.Tensor 'IteratorGetNext_34:15' shape=(?,) dtype=string>), ('Start Time', <tf.Tensor 'IteratorGetNext_34:16' shape=(?,) dtype=string>), ('End Date', <tf.Tensor 'IteratorGetNext_34:5' shape=(?,) dtype=string>), ('End Time', <tf.Tensor 'IteratorGetNext_34:6' shape=(?,) dtype=string>), ('Event Title ', <tf.Tensor 'IteratorGetNext_34:8' shape=(?,) dtype=string>), ('All Day Event', <tf.Tensor 'IteratorGetNext_34:0' shape=(?,) dtype=string>), ('No End Time', <tf.Tensor 'IteratorGetNext_34:13' shape=(?,) dtype=string>), ('Event Description', <tf.Tensor 'IteratorGetNext_34:7' shape=(?,) dtype=string>), ('Contact ', <tf.Tensor 'IteratorGetNext_34:2' shape=(?,) dtype=string>), ('Contact Email', <tf.Tensor 'IteratorGetNext_34:3' shape=(?,) dtype=string>), ('Contact Phone', <tf.Tensor 'IteratorGetNext_34:4' shape=(?,) dtype=string>), ('Location', <tf.Tensor 'IteratorGetNext_34:10' shape=(?,) dtype=string>), ('Category', <tf.Tensor 'IteratorGetNext_34:1' shape=(?,) dtype=int32>), ('Mandatory', <tf.Tensor 'IteratorGetNext_34:11' shape=(?,) dtype=string>), ('Registration', <tf.Tensor 'IteratorGetNext_34:14' shape=(?,) dtype=string>), ('Maximum', <tf.Tensor 'IteratorGetNext_34:12' shape=(?,) dtype=int32>), ('Last Date To Register', <tf.Tensor 'IteratorGetNext_34:9' shape=(?,) dtype=string>)])\n"
     ]
    }
   ],
   "source": [
    "path=\"sample.csv\"\n",
    "data_csv=tf.contrib.data.make_csv_dataset(path, batch_size=32)\n",
    "iter = data_csv.make_one_shot_iterator()\n",
    "next = iter.get_next()\n",
    "print(next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011', b'9/5/2011',\n",
      "       b'9/5/2011', b'9/5/2011'], dtype=object), array([b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School',\n",
      "       b'High School', b'High School', b'High School', b'High School'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = next['End Date'], next['Location']\n",
    "with  tf.Session() as sess:\n",
    "    print(sess.run([inputs, labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47194223, 0.00933356])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterator types: one shot,initializable,re-initializable,feedable\n",
    "data = np.random.sample((100,2))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47194225 0.00933356]\n"
     ]
    }
   ],
   "source": [
    "#Initializable Iterator\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "dataset_it = tf.data.Dataset.from_tensor_slices(x)\n",
    "iter = dataset_it.make_initializable_iterator() # create the iterator\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iter.initializer, feed_dict={ x: data }) \n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reinitializable Iterator:The concept is similar to before, we want to dynamic switch between data. But instead of feed new data to the same dataset, we switch dataset. As before, we want to have a train dataset and a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "test_data = (np.random.sample((10,2)), np.random.sample((10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets, one for training and one for test\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a iterator of the correct shape and type\n",
    "iter = tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initialisation operations\n",
    "train_init_op = iter.make_initializer(train_dataset)\n",
    "test_init_op = iter.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.90332682, 0.0697792 ]), array([0.54479065])]\n"
     ]
    }
   ],
   "source": [
    "# Reinitializable iterator to switch between Datasets\n",
    "EPOCHS = 10\n",
    "# making fake data using numpy\n",
    "train_data = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "test_data = (np.random.sample((10,2)), np.random.sample((10,1)))\n",
    "# create two datasets, one for training and one for test\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "# create a iterator of the correct shape and type\n",
    "iter = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                           train_dataset.output_shapes)\n",
    "features, labels = iter.get_next()\n",
    "# create the initialisation operations\n",
    "train_init_op = iter.make_initializer(train_dataset)\n",
    "test_init_op = iter.make_initializer(test_dataset)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(train_init_op) # switch to train dataset\n",
    "    for _ in range(EPOCHS):\n",
    "        sess.run([features, labels])\n",
    "    sess.run(test_init_op) # switch to val dataset\n",
    "    print(sess.run([features, labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read a image to a string\n",
    "\n",
    "img=tf.read_file(\"1308.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'GIF89a\\xb4\\x00d\\x00\\xf7\\x00\\x00\\x07\\x07\\x07\\xff\\xff\\xffPPPooo---\\x8e\\x8e\\x8e\\xad\\xad\\xad\\xd4\\xd4\\xd4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00,\\x00\\x00\\x00\\x00\\xb4\\x00d\\x00\\x00\\x08\\xfe\\x00\\x03\\x08\\x1cH\\xb0\\xa0\\xc1\\x83\\x08\\x13*\\\\\\xc8\\xb0\\xa1\\xc3\\x87\\x10#J\\x9cH\\xb1\\xa2\\xc5\\x8b\\x183j\\xdcH\\xf1\\x80\\xc7\\x8f\\x078\\x8a\\x1cI\\xb2d\\xc7\\x01\\x04\\x00\\xa8\\\\\\t\\x80\\xc0\\x80\\x02!M\\xca\\x9cI3\\xe3\\x01\\x01-\\x05\\x0c\\xd8)\\xa0\\'K\\x035\\x83\\n\\x1d\\x9a\\xf0\\x00\\x01\\x02\\x05\\x06\\xe0\\xcci\\xc0\\xc0\\x80\\x96\\x05\\x88J\\x9dZ\\xd3(\\x01\\x03)\\x01\\xbcL\\x9a\\x12)\\xd5\\xaf`7\\x1ep\\xba\\x13k\\xcb\\x03\\x05\\xb2\\x02\\x10\\x103\\xac\\xdb\\xb7\\x0e\\xc7\\x16\\x10pT\\xe9J\\x01N\\x0b\\x18\\x98\\xabR\\x00L\\xb8\\x80\\x03\\x0bD\\x8bw\\xaf\\xda\\x95GS\\x16X\\xcc\\xb5/P\\xc1\\x90\\xbf\\xf2\\xec\\x89w\\xa9\\xca\\x97d\\xb5v\\xd5\\x9b\\xf6r\\xdb\\xc8\\xa0g\\xeeU\\x8a\\xf4\\xe9\\xe2\\x9e|\\r\\xe0\\x9c\\xfb\\xd4\\xa5\\xce\\xb1O\\xd7~\\x0eM\\x9b#c\\xd2/);\\xa5K\\xc0\\xa8\\xce\\xb4I\\x93\\xae5\\x80\\xb6\\xef\\xec\\xda\\xc8)\\x1an\\xaa\\xd9.R\\xbc\\x05\\x00\\x8c\\xd5\\xca\\x1akZ\\x97z\\x8bk\\x8d\\x0c\\xd2\\xe3\\xde\\xec\\xc7\\x93\\xfe\\'\\x14~zgV\\xe0~\\x01\\xc0\\xd4\\xfa\\xd2|\\xda\\xf6\\xaa\\x89\\xb7\\x0eO\\x14\\xadR\\xbf\\xde\\x197m\\x1a\\x9c\\xbex\\x81\\x86\\xa9\\xc7\\xd9R\\xa4Eg\\xe0\\x01\\xb2m\\xb5\\xd8e\\xf2\\xe1\\x15\\x80\\x01*=&\\x95j}\\xe9E\\xdcuG\\xd1\\xe5\\x17q\\xb0\\r\\xe0_r\\xe9\\x95\\xa6Vo*\\x11\\xa0\\x13\\x00\\xc4\\x95\\xb8\\x17e\\x93m\\xf5\\x94\\x87\\xab\\rE\\xe1es\\xa5\\xd4\\x13RI\\xed\\xa4#O\\x1e\\xde\\xe4\\xe1\\x7f\\x04\\xe5\\xa6\\x1e]}U\\xa8\\xd8YW\\x99%\\xdf\\x8e\\x0b\\xde\\xb5\\xd5v3\\xa1\\x95\\x15~\\xbb\\xa5\\xa4\\xd4u:\\x9ef\\xe2b^E\\xf7\\xe3\\x7fXA\\xc8\\xd6\\x90\\x8c\\xe1T\\xd8jt\\r\\xf4\\xd4t\\xec\\xe9d\\x96z)M\\'\\x80Lo^\\x15\\x80\\\\J\\xe9xbn\\xbfI\\xa9\\x15\\x84\\xbdA\\xa8\\x9exFQx\\xd3U7\\xe2X\\xe2UOI\\x18\\x00J\\x01\\xfc6\\xc0\\x8aJ\\x96\\xe8\\xd1Q\\x1fN\\xe4\\xe7p\\x01t\\x96\\x13\\x91-a\\xe5\\x93O\\xc3\\xe1$\\xa4G+}\\x19\\x9aK\\x8d6j\"n\\xfe\\xd1!u\\xc0\\x8b\\x05!\\xa8\\xd7\\x95\\xaeq\\x15[\\x84\\x8f\"\\xf5]v\\x9a\\xf2\\xb5\\x16gvA\\xc5\\x9ap\\xa1\\xbe\\x9aW\\xab&\\xaa\\x87\\x12\\xaa\\x889\\n\\xd8M\\xe9\\xe1\\xc5\\xdeZ~\\xc1\\xf4\\x92v\\x03\\x1c\\xd4(Y/]e\\xe2j\\x9du+hKG\\xb54iC\\x84\\xd5\\xc5\\x1fN\\xe9\\xfe\\xd9U\\x89\\x9d!ZZ\\x8d\\x80\\xa2\\xc4*\\x01\\x8f\\x0e\\xb7Y`\\xefE\\'\\x9d\\x89\\xa2\\xb6\\xa7\\xa7q\\x08!\\xc8\\x96\\x8b\\x14\\xe2\\xa6\\x1e\\xa7c\\xed7\\x1ao\\xaa\\x0eV\\xe5\\xb0c\\x8du\\xe2Z\\xa1>\\xe5\\xd7\\xa4K\\xf1\\xc5(\\xba\\x0b\\xf7u\\xe3\\\\s\\xa6\\x04\\x94\\xa7Q\\x85\\xa5\\x1a^\\xb19%\\xdd\\xc4\\xf7\\xf54i\\xa6\\xad\\xead\\x19J\\xd9\\xeate\\xa7\\x96e\\xa8\\x97\\x8dI\\xb1\\x88YH\\xefaUs\\xb2\\xd4e\\xf5\\xe6K*\\xdd\\xda\\x14\\x81\\x1a6\\xba\\xe1Z\\x03\\xcd\\x1a*Uh]\\xb8\\xd2\\xd05\\xe2\\x95i\\xc2gM\\xba\\xeb\\x8d\\x94\\x9d6V\\xb3[Q\\xc8\\x96\\xa0\\x1e\\xf2\\xb7XS\\x8aY\\x97\\xe7j1\\xe3\\xb5%\\xfeK.Y\\x89\\x92q\\xfbe%\\xeeM(\\x12d\\x14\\x94C%\\xc5\\xdfy\\xa2\\xcaz\\x91\\xab(\\n\\x8c\\x14{\\xac\\x86\\xa4\\xa1OG\\xe9\\xc5\\xab\\xa96\\x0b\\xd9\\x9b\\xc0,\\xa6jj\\xc0\\x82\\x8f\\xeb\\xa9cYy8\\xa5R\\n\\x1bd\\xe6\\xd8\\x1a\\xbd\\xbc\\x94\\xcf+6j\\x93\\xb3\\x9e)\\x06/]\\xdd\"8\\xeeZ\\xe6Y;\\xe8u+\\x86\\xaa5K\\xc8_\\xeb\\x17\\xbc\\x985\\xf5\\xd1R\\x93W6\\xdc\\xd7CJgPl-\\xcb\\xe4;\\xcfl\\x11fm\\xf6\\x18\\x11\\xdc\\x12\\x8a\\x80b\\xa9Uq\\xe36\\x8b\\x94\\xa2.\\x11\\xe7\\xd4G\\xfd\"\\x1fh\\xb1\\x7f\\n\\xfc)\\xa8\\xc3\\xab\\x0b\\'\\x85\\xc8\\x92\\x06!\\xf8\\x03\\tY\\x94Lf\\xb3\\xe0\\x00\\xc76\\x03\\xa3\\x90\\xccr\\xa2\\x18\\xa8\\xa5o5}k\\x18\\xe0\\xc2f\\x9e\\xafue+\\x87\\xd1\\x93\\xd0DF\\x9cjy,T\\xd4\\xc3\\n\\xbf\\x0c2+S\\xcd$Vm\\xd3X\\xc5n\\x87\\xb2\\xbf\\t*W\\xaai\\riP\\x93\\xa11\\xb9\\x10z\\xa4\\xb9\\n\\xbd(\\x07\\xbc\\n=\\x89U\\xfeU{\\x91G^\\x14\\x1b\\xe7\\xa0\\x08%\\xd1\\x91\\x96@*8\\'\\xed\\xdd\\xc7B\\xc4)\\x89\\xcd\\xe8\\xf2\\x1e\"~\\xacX(AI\\x0c]\\x82\"\\x13\\xb9\\xe62;\\xf1\\x8d\\xc0\\n\\xf4\\xbd\\xccm\\xeb=\\x87*\\x9a\\x9e\\x1c\\xe4\\xb1\\xc5\\x10\\xb1}p\\x1a\\xa1A\\x90\\xd5\\x1b )\\xe4\\x7f}\\xd3\\xa2V\\xdc4\\xb9\\xcbP\\xac\\x8a\\x94\\xd3\\x89\\x95\\xe8\\xa2\\x1aqEh\\x8f\\x06{\\x0eqT\\xd6+\\xf4\\x8dKgQ\\x89MW\\xbc\\xd8\\x9e\\xf4\\x000k\\x98\\x83\\x1drlu\"\\xdeU\\r\\x8f\\x17\\xe4\\x18\\xb2\\xaeUA\\x1d\\xa9\\x0c\\x87\\xd2\\xe1\\x1dp\\xd4\\xd3:\\x81D\\xceYX\\x02\"\\xe1\\x16\\x05!$F/!\\xc5k\\xa2\\x1d\\x0f\\xb2%.\"\\xd1d\\xa5\\xd9\\xc9\\x1e9f\\xb6\\xa1\\xad\\xa5o\\xe3\\x93\\x9e\\x05\\x93\\xa4\\x9a\\xe8\\xb0\\xc5%Y#\\xd1\\xdf\\xaa\\x97\\xa7\\xb9h\\xa7Y\\'bM\\x9cp)(\\xb6\\x1c\\x04$\\xc9i\\xd4\\x90~\\t\\'\\x9d\\xe9\\xcf|\\xd8*\\x11\\xf3\\\\T!z\\xc1\\x8bK\\xfc\\xea\\tA\\xb6\\xd8\\x13\\x99\\xa1,-\\'\\xfe\\xa2\\x1b\\xf04$./-dJ$\\xec\\xcbK\\x90\\x03\\xa1\\x86\\xf1Ne\\xd8\\x9a\\x1d\\xef\\xd4e\\x19\\xad\\x94\\x08y~9\\xca\\xd3\\x18\\xd3\\x92^\\x15Dv}[\\xdfdlv>I\\x8e\\xeb>\\xb6\\xc3e\\xaa\\n\\xd2\\x9a\\xc4h\\xf2+\\xb6\\xf2\\x12epRK/\\xaer\\x9a:\\x13$vv\\xe6\\xb1z\"F`\\xcc\\x99\\x8d\\xd2\\xb2x\\x1d\\x9f\\xa1-\\x00V\\xea\\x14\\xba\\xfc\\xa7\\x19\\xeb%dc\\x8eb\\xa9\\x02\\x91\\x83)u\\xf1L\\x87O\\xdd\\x91C\\x93\\xc7\\x9b\\xa9\\xfe\\xad\\x89\\x1ce\\tL\\xecT\\xab\\xe5\\xe1sn\\xae\\xf1\\xd8\\x9dl$\\x10\\x95\\xe2\\xce.\\x97\\x1c\\x88>\\x0bW\\xd6cz\\xe9\\xa4T\\x89\\x8e\\xd6\\xd069/\\x855V\\xeb\\xac\\xcb\\xf2\\xf4\\xf5\\xba\\xab\\x18H-0R\\xa2@t\\xf81P\\xbd\\x07k\\x02\\x11`\\x9d\\xfa%Lo\"\\xe4\\\\\\xdd\\xba\\x93\\xa9j)\\xd8\\xc0\\xfc\\x0f\\xa8\\xf73\\xd01}\\xda\\x9a=j\\x94{Vr(\\xe6\\xec\\xa7\\x17\\xc7\\x1e\\xc4g\\x02\\x9d\\x9bf\\xcf\\xd7\\xd6\\xa8\\x1d\\xefm\\x1bR\\xfe\\xccQ9\\xe68\\x8f\\xf0\\x0e\\xaeS\\x89\\xd5\\x83\\x1e\\n\\xb51\\xb6\\xa9\\xa4\\xc1\\xb3\\x91\\xa9\\x84\\x9bN\\x98,Ec\\x1f*\\xe8\\xae\\x1ez\\xbe\\xa5<FcP\\x99\\xd1\\xdb.d\\xb3(\\x1an}\\x88\\x11\\x9c.C\\xc3\\x9b9YfA\\xa0\\xa3\\xe21\\x133:=\\xedj2Q\\x81\\xd7\\x8a\\xc6\\xf6\\xad\\x86~\\xed4\\xb2\\xc1$T4\\xd6>\\xfe\\xac\\xc8Fm\\xe9\\xda\\xbc~\\xc2T\\xad\\xa9\\xce\\xb5\\x0f\\xeb\\x8b\\x19\\x9b\\x15\\xb5\\x97I\\xd5I\\xd2\\xb3\\xd7CP8#\\x96d\\xe9\\xb6Y\\x8b\\xcd\\x86\\x0c\\x0c\\xd2\\xb5\\xd5\\xf1\\xba\\xbf\\x01Vm\\x8c\\x12)\\x95@+*}\\xbc\\xccCC\\xa6E\\xb2\\x1c\\xb4\\x87\\x8d\\x9d\\x0fD\\x0e\\xd5\\xbei\\x1a)\\xa2\\x83\\x9a\\xe7\\xec\\x06$$\\xe8\\xb0\\xd5p\\xb8u\\xd9\\x98\\x1ck\\x1a\\xa0\\x9ae\\xa5S\\x1a\\x12[4\\x04\\x15\\xec\\xc8\\x90\\x8b1\\x0e\\x16\\x8b\\x1a\\xc3(D\\x01\\xe0\\xb13.Kg\\xb8\\x94c\\xc1\\xcc\\x05+\\x0fb\\x1d4\\xd7\\xf7\\x9c\\x1c]\\xee\\x7fP!Ph\\xc7{\\x16\\x9b\\xa8W;\\xd6\\t\\xc0\\xfe\\x8dIx\\xb6\\xbf\\xb0T)\\xbb,\\x88\\xe2\\nI1\\xa04\\x87\\x92(\\xeb\\x8d\\x177\\x96\\xbc\\xdf\\xb1V,\\xfa*m\\xd4\\xd4<6\\xa7\\xd8\\x08(\\xa6\\xf1J\\x9c\\xcb\\xaa-.f\\xd3w\\xd5\\x05)u\\xb0\\x85 \\xf9Q\\xc6JUv\\x88Y\\x14\\x99\\x96\\x15_\\x87Ki\\xa9lr\\x16\\xa3\\xe6\\x9e\\x92\\x8a\\xa1<y\\x8f\\xb8~\\x06\\xc5\\x1c\\xce\\xb7&\\x05]Od#\\x92/\\xd2,\\xfaQQ\\x112>\\xc7\\xf7\\xb0r\\xf1\\x14N\\x93*Zb\\xb6E\\x14\\xbf\\x16\\xb4#xS\\xf4.w\\xa2f\\xcd\\x1c\\x96\\x7f\\xc3\\xed\\x8c\\xd6\\xe2\\xa5.\\xebN\\x05G\\x9d\\xb6\\x88\\x81\\x089\\x94\\x88Y(b\\xfb\\xe9\\x8e\\xb8?\"\\xaa\\x0eW\\xc6g\\xfdJ\\x0f\\xba\"\\xa4l\\xc0\\x18y\\xbb\\xca)\\x8diM\\xc2\\xe2\\xcb\\xad4Q\\xd4N\\x1eb\\xe6t\\xb8\\x08E\\xb6\\xd2\"\\x04\\x95Q\\xd2\\x1a\\x96}\\x89\\x1a\"\\x01\\x9b\\xf7H(;\\x1a/?\\xf27\\x1c\\xf2\\x0e\\x87\\xc2MR\\xf6HH\\x88\\xbc[S\\x92\\x01\\xa339b\\xa4\\x9a\\n\\xe7\\x88\\xaf\\xfe\\x9c\\x975r\\xdf7\\'\\xc4\\x862t\\x92b8\\x10\\xd2\\x10A\\x07\\xa7J\\xc7E\\x8e\\x19xo$\\x89\\xdaR\\x10c\\xe6\\x16\\x92\\xfcLfK\\xd6\\xf6koV\\xc89O\\xc2\\x1c2?\\xdd\\x88\\xd2\\x82C\\x92z:\\'1\\x87\\xc9n\\x01o\\xd3]\\xe3.\\xcfA\\xb5\\xb2R\\xfal\\x85t\\r\\x89\\x84\\xa7~\\x11\\x89Qf\\xf5\\xac\\x84I\\xdc\\xe1]\\xe9\\x1c\\xbeY\\xf5\\xd8\\x9cXj\\xe3p\\xe9\\xeeH2\\x14\\x1f\\x8e\\x9ci]\\x1d\\x91K\\x8e\\x9e\\x18\\xf2\\x81\\xc4*+@\\x9d5\\xc7\\xeb\\xb2\\xf0\\x9c\\x84Z#\\xaf\\xc1\\x91\\xd8)\\xae\\x10\\xceIG\\xae\\x82\\xa1\\x18I\\xc4\\xe4\\xc2\\x8bP\\xebA\\x8b\\xc94F\\x14v\\xb8n!.\\xee\\xbc+\\xc9\\x9a\\x94T\\x91\\xce\\x975\\xe62\\xc1\\xc9,\\xd7\\x83z\\xa2\\xc4\\xb4$\\n{\\x194%\\xe2\\xcc)\\x12\\xbc*\\xe4\\xbbL\\xa4\\x04\\x0f\\xfa4\\x95\\xc4\\xae}\\xeb\\xfbl\\xa7v(\\xb0\\xd0\\xa5\\xd2s\\x9aKdP\\xa3\\x13\\x93H4\\\\\\xc7o\\xc8\\xcb\\x92b\\x95\\x0bO\\x05\\xe6\\xad\\x19\\xab\\xe6S\\xfe\\xbf\\xb8\\xed+\\x04\\xfb-J\\xd8nV*\\x1b\\x13y\\xff\"6\\x95\\xce\\xc0As\\xb3\\x1a\\x9d\\x1f!ZT;\\x00\\x0b\\xb9\\xa8\\xd5\\xe1\\xfd+\\xcaE\\x91QxoY\\xac\\x94\\xd0\\xe3\"\\xb1%hd}V\\xc1k\\xf8v{C\\xd1T\\xddr\\x14\\xb4150\\x03wJ7\\x1c\\xff#O\\x01\\x84.Pw3oa\\x1a\\x90\\xb2&\\xb4\\x111G4{$\\x81W\\xf3\\xf2\\x19\\xd3\\xe4\\x12\\xef\\xa7\\x11\\xbe\\x03s\\xc7V\\x1b\\x1e\\xf2[\\xdaS<ef8\\xd6\\x06\\x18\\x8dB}\\x88\\xc5\\x82KB\\x8141+\\'X\\x13H\\xa25=H\\'\\x85QH\\xb7&\\x13I\\xc4:kV\\x1b\\xbeTvE\\xd8tzVB@Bd\\xa1\\xd7\\x84b\\xb7G\\xcfdG\\x90\\x96\\x18T\\xf8u(\\x82\"X\\x07$\\xd4\\x02x[\\xb8\\x11\\xfb\\xe4\\x14\\xb7\\x163c\\x18;]\\xc4\\x83E\\x88\\x13i\\x88x]\\xc6\\x7f\\xbb\\x14\\x84Th+\\xebC\\x87o\\xb8hY\\x84\\x1ay\\xd8\\x87\\x12a\\x87\\xd9\\xe6\\x87\\x82\\xd8\\x105\\x03g\\x83x\\x88\\x84E!Ha\\x82\\x88\\x8c\\xd8U\\xa1f\\x88\\x8d\\xd8\\x88\\x03\\x87)\\\\\\x15\\x89\\x888v,\\xa5|\\x96x\\x89\\x8c\\xa2\\x14\\xfe\\xb7\\x89\\x888\\x84\\xe0\\x02\\x8a\\x87\\xb8!\\x91\\xc4\\x84\\xa4\\xd8\\x87\\xd9\\xa28\\xaf\\x92\\x8a~\\xe8&\\xac\\xa1\\x88\\xae\\xf8\\x86i\\xc43\\x9ehT\\xb3xky\\x81WS\\xf4L6\\x97\\x8b`\\x98\\x18{dh=d}\\xc0\\xb8lf\"L\\xe8\\x15_\\xc7\\xb8hU\\x13|\\x02\\xd5z\\xcd\\x18\\x1a\\xf6\\xa3N\\x1c2\\x8du\\x18nx\\x88\\x8d\\xdc\\x88\\x88\\x01\\x01\\x00\\x00;'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_from_string=tf.image.decode_jpeg(img,channels=3) #converts string  to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(img_from_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=tf.image.convert_image_dtype(img_from_string,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=tf.image.resize_images(image,(96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for parallel calls --> num_parallel_calls=5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0) # Make sure the image is still in [0, 1]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a text data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=tf.data.TextLineDataset(\"features.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=tf.data.TextLineDataset(\"labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.zip((feature,label))\n",
    "res=dataset.shuffle(5).batch(4).prefetch(1).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([b'tensorflow', b'in tf.data', b'on stanford', b'first'],\n",
      "      dtype=object), array([b'2', b'4', b'5', b'1'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(res))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
